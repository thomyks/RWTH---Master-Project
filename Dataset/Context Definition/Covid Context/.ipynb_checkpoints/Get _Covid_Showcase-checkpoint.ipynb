{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b528a9a-f9db-47c7-90f9-0ba37b0ee063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d8e02d6-3b5c-44ed-87f0-8cc259375bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace file path with custom one if necessary\n",
    "df = pd.read_csv('preprocessed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6f92695-24b1-4de4-8f76-2c9e1be2820f",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_string = 'Covid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1ce8568-c57b-45e1-a5a0-2ec7c5e4220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define set of synonyms and other keywords which will be searched for in the claim texts and entities \n",
    "# note: synonyms or keywords that contain the entitiy string, i.e. 'covid', don't need to be included,\n",
    "# because they will be found while scanning for the entity string itself\n",
    "synonyms = [\n",
    "    \"Corona\", \n",
    "    'vaccin',\n",
    "    'lockdown'\n",
    "    'China Virus',\n",
    "    'Wuhan Virus',\n",
    "    'pandem',\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6657920d-8b96-48c1-a1bc-952e4cdd3a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define words that are keyword itself or present in synonyms that might be included in some synonyms\n",
    "minimal_words = ['Covid']\n",
    "# discard the synonyms that contain one of the minimal words\n",
    "new_synonyms = list(filter(lambda s: not any(mw.lower() in s.lower() for mw in minimal_words), synonyms))\n",
    "# split synonyms into words\n",
    "# note: ngrams comparison approach only needed for efficient check for multiple different synonyms. with only two synonyms it's okay to just check for substring matching\n",
    "splitted_synonyms = list(map(lambda s: s.split(' '), synonyms))\n",
    "# determine length of longest synonym to know how long ngrams will need to be\n",
    "ngrams_length = max(list(map(lambda words_array: len(words_array), splitted_synonyms)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e038e7fe-aea3-4df6-88af-a56227e54e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(row):\n",
    "    # check if entity string is present in string of all entities\n",
    "    if type(row.entity_strings) == str and entity_string.lower() in row.entity_strings.lower():\n",
    "        return True\n",
    "    # check if entity string is present in text\n",
    "    elif entity_string.lower() in row.text.lower():\n",
    "        return True\n",
    "    # check if any synonym is present in string of all entities\n",
    "    elif type(row.entity_strings) == str and any(synonym.lower() in row.entity_strings.lower() for synonym in new_synonyms):\n",
    "        return True\n",
    "    # check if any synonym is present in text\n",
    "    elif any(synonym.lower() in row.text.lower() for synonym in new_synonyms):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f51fbac-d05b-4bbe-ba7b-e50707db6dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = df[df.apply(filter_df, axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e0d44f8-590c-481b-b6c1-1734c4fb6560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5274"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(covid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0471ae24-5eff-4baa-9115-2a44cacfb36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df.to_csv('covid_df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
