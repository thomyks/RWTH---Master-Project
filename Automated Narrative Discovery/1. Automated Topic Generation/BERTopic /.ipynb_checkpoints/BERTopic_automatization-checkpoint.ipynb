{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a7909c-2d06-4469-bff5-19239982cf3a",
   "metadata": {},
   "source": [
    "# Automated Topic Modelling with BERTopic\n",
    "\n",
    "## Overview\n",
    "\n",
    "This Jupyter Notebook demonstrates the process of topic modeling using the BERTopic library. \n",
    "\n",
    "## Process\n",
    "\n",
    "1. **Environment Setup**: \n",
    "    - Import necessary libraries: BERTopic, NLTK for stopwords, OS, and Pandas.\n",
    "    - Set an environment variable to disable parallelism in tokenizers, ensuring thread safety.<br>\n",
    "\n",
    "2. **Dataset Loading**:\n",
    "    - Load Dataset.<br>\n",
    "\n",
    "3. **BERTopic Modeling**:\n",
    "    - BERTopic: Basic BERTopic with multiple iterations with KeyBert fixed labelling\n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb15c0b7-619d-472e-9004-d2c998ed98f4",
   "metadata": {},
   "source": [
    "1. **Environment Setup**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a509894a-bb4c-40b2-ac04-56f177b6fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from bertopic import BERTopic\n",
    "from nltk.corpus import stopwords\n",
    "from bertopic.representation import KeyBERTInspired \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eee1e22-6834-4e9f-a2c5-ad31afa3c8a8",
   "metadata": {},
   "source": [
    "2. **Dataset Loading**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1cfbb66-88cf-4225-81df-e8c6318927f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe = pd.read_csv('biden_df_12_01.csv')\n",
    "dataframe = pd.read_csv('covid_df_20_01.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5927094d-2186-4201-a8c2-7ee065fe225e",
   "metadata": {},
   "source": [
    "3. **BERTopic Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d44216-5148-4b91-acc4-1518fcde3f73",
   "metadata": {},
   "source": [
    "      - Version 6: Basic BERTopic with multiple iterations with KeyBert. Fixing the labelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265b6c5f-e53a-471d-88ea-a9b4e8c71091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the environment variable to disable parallelism\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def process_dataset(dataframe: pd.DataFrame, dataset_name: str, num_runs: int) -> None:\n",
    "    # Initialize the representation model\n",
    "    representation_model = KeyBERTInspired()\n",
    "\n",
    "    # Specify the embedding model to be saved with the BERTopic model\n",
    "    embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "    for run_number in range(1, num_runs + 1):\n",
    "        run_folder = f\"BERTopic_run_{run_number}\"\n",
    "        os.makedirs(run_folder, exist_ok=True)\n",
    "\n",
    "        if run_number > 1:\n",
    "            # Correctly load the outliers from the previous run\n",
    "            outliers_filename = os.path.join(f\"BERTopic_run_{run_number - 1}\", f\"BERTopic_run_{run_number - 1}_Outliers.csv\")\n",
    "            try:\n",
    "                dataframe = pd.read_csv(outliers_filename)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File {outliers_filename} not found. Ending the process.\")\n",
    "                break\n",
    "\n",
    "        # Create BERTopic model with the custom representation model\n",
    "        topic_model = BERTopic(\n",
    "            language=\"english\",\n",
    "            calculate_probabilities=True,\n",
    "            verbose=True,\n",
    "            representation_model=representation_model  # Add the custom representation model\n",
    "        )\n",
    "\n",
    "        topics, probabilities = topic_model.fit_transform(dataframe['text'])\n",
    "\n",
    "        # Generate topic names and update the dataframe with these names\n",
    "        topic_info = topic_model.get_topic_info()  # Get topic information\n",
    "        topic_names = {row['Topic']: row['Name'] for index, row in topic_info.iterrows()}\n",
    "        dataframe['Topic'] = topics\n",
    "        dataframe['Topic Name'] = dataframe['Topic'].apply(lambda t: topic_names.get(t, 'Unknown'))\n",
    "\n",
    "        # Save the dataframe with topic labels using the updated naming convention\n",
    "        labeled_data_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_TopicLabels.csv\")\n",
    "        dataframe.to_csv(labeled_data_filename, index=False)\n",
    "\n",
    "        # Save 'Topic Name' column to a npy file using the updated naming convention\n",
    "        npy_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_TopicNames.npy\")\n",
    "        np.save(npy_filename, dataframe['Topic Name'].values)\n",
    "\n",
    "        # Save BERTopic results with the updated naming convention\n",
    "        bertopic_results_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Topics_Results.csv\")\n",
    "        topic_info.to_csv(bertopic_results_filename, index=False)\n",
    "\n",
    "        # Save documents for each topic using the simplified naming convention\n",
    "        for topic, name in topic_names.items():\n",
    "            if topic != -1:  # Excluding outlier topic\n",
    "                topic_indices = dataframe[dataframe['Topic'] == topic].index\n",
    "                topic_dataframe = dataframe.loc[topic_indices]\n",
    "                clean_name = name.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                topic_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Topic_{topic}_{clean_name}.csv\")\n",
    "                topic_dataframe.to_csv(topic_filename, index=False)\n",
    "\n",
    "        # Handle outliers, saving them with consistent naming\n",
    "        outlier_indices = dataframe[dataframe['Topic'] == -1].index\n",
    "        if len(outlier_indices) > 0:\n",
    "            outliers_dataframe = dataframe.loc[outlier_indices]\n",
    "            outliers_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Outliers.csv\")\n",
    "            outliers_dataframe.to_csv(outliers_filename, index=False)\n",
    "        else:\n",
    "            print(\"No outliers found in this run. Ending the process.\")\n",
    "            break\n",
    "\n",
    "        # Save the BERTopic model using safetensors serialization\n",
    "        model_dir = os.path.join(run_folder, \"model_dir\")\n",
    "        topic_model.save(model_dir, serialization=\"safetensors\", save_ctfidf=True, save_embedding_model=embedding_model)\n",
    "\n",
    "        print(f\"Run {run_number}: Model and data saved successfully in {model_dir} using safetensors serialization.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff7c9f31-3900-4172-8ea7-17ce302665d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-25 21:55:06,301 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74457a639eb4921a92c5bad63acf0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-25 21:55:10,349 - BERTopic - Embedding - Completed ✓\n",
      "2024-02-25 21:55:10,350 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-02-25 21:55:38,024 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-02-25 21:55:38,028 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-02-25 21:55:41,371 - BERTopic - Cluster - Completed ✓\n",
      "2024-02-25 21:55:41,378 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-02-25 21:55:43,287 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1: Model and data saved successfully in BERTopic_run_1/model_dir using safetensors serialization.\n"
     ]
    }
   ],
   "source": [
    "# process_dataset(dataframe, dataframe_topic_summary_give a name, num_runs)\n",
    "process_dataset(dataframe, \"BERT_Topics\",1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
