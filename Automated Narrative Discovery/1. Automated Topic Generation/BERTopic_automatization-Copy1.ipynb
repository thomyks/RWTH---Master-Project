{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a7909c-2d06-4469-bff5-19239982cf3a",
   "metadata": {},
   "source": [
    "# Automated Topic Modelling with BERTopic\n",
    "\n",
    "## Overview\n",
    "\n",
    "This Jupyter Notebook demonstrates the process of topic modeling using the BERTopic library. \n",
    "\n",
    "## Process\n",
    "\n",
    "1. **Environment Setup**: \n",
    "    - Import necessary libraries: BERTopic, NLTK for stopwords, OS, and Pandas.\n",
    "    - Set an environment variable to disable parallelism in tokenizers, ensuring thread safety.<br>\n",
    "\n",
    "2. **Dataset Loading**:\n",
    "    - Load Dataset.<br>\n",
    "\n",
    "3. **BERTopic Modeling**:\n",
    "    - Version 1: Basic BERTopic\n",
    "        - Instances of BERTopic execution: 1\n",
    "    - Version 2: Basic BERTopic with KeyBERT \n",
    "        - Instances of BERTopic execution: 1\n",
    "        - Fit the model on the 'Text' data. This involves the transformation of text data into topics.\n",
    "        - The representation layer is improved by using KeyBERT      \n",
    "     - Version 3: Basic BERTopic with multiple iterations\n",
    "        - Instances of BERTopic execution: n. \n",
    "        - The n+1 iteration happens on the outliers. \n",
    "        - Save the dataframe used for topic modeling to a CSV file, including the topic labels. After topic modeling, the dataframe used for topic modelling is updated with two new columns: 'Topic' and 'Topic Name'.\n",
    "        - Save the 'Topic Name' column of each row to a .npy file (NumPy file format)\n",
    "      - Version 4:Basic BERTopic with multiple iterations with KeyBert\n",
    "        -  Instances of BERTopic execution: n. The n+1 iteration happens on the outliers. \n",
    "        - Fit the model on the 'Text' data. This involves the transformation of text data into topics.\n",
    "        - Save the dataframe used for topic modeling to a CSV file, including the topic labels. After topic modeling, the dataframe used for topic modelling is updated with two new columns: 'Topic' and 'Topic Name'.\n",
    "        - Save the 'Topic Name' column of each row to a .npy file (NumPy file format).\n",
    "        - The representation layer is improved by using KeyBERT    \n",
    "    - Version 5: Basic BERTopic with multiple iterations fixed labelling\n",
    "    - Version 6: Basic BERTopic with multiple iterations with KeyBert fixed labelling\n",
    "    \n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb15c0b7-619d-472e-9004-d2c998ed98f4",
   "metadata": {},
   "source": [
    "1. **Environment Setup**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a509894a-bb4c-40b2-ac04-56f177b6fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from bertopic import BERTopic\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eee1e22-6834-4e9f-a2c5-ad31afa3c8a8",
   "metadata": {},
   "source": [
    "2. **Dataset Loading**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1cfbb66-88cf-4225-81df-e8c6318927f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe = pd.read_csv('biden_df_12_01.csv')\n",
    "dataframe = pd.read_csv('covid_df_20_01.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5927094d-2186-4201-a8c2-7ee065fe225e",
   "metadata": {},
   "source": [
    "3. **BERTopic Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb91165-66ac-48d5-83cd-dfbe0c25a608",
   "metadata": {},
   "source": [
    "    - Version 1: Basic BERTopic\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bed4572-e009-464b-be5d-018ec8ef62d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 20:47:25,259 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f40aec551ef45d7a777a4ab2688685c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 20:48:13,640 - BERTopic - Embedding - Completed ✓\n",
      "2024-02-06 20:48:13,641 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-02-06 20:48:24,176 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-02-06 20:48:24,177 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-02-06 20:48:24,331 - BERTopic - Cluster - Completed ✓\n",
      "2024-02-06 20:48:24,335 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-02-06 20:48:24,403 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "# Set the environment variable to disable parallelism before importing 'tokenizers'\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Load English stopwords from NLTK\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "# # Assuming you have a DataFrame named 'dataframe' with a 'Summary' column\n",
    "# # Apply stopword removal to the 'Summary' column\n",
    "# dataframe['cleaned_summary'] = dataframe['Summary'].astype(str).apply(\n",
    "#     lambda x: ' '.join([word for word in x.split() if word.lower() not in english_stopwords])\n",
    "# )\n",
    "\n",
    "# Create BERTopic model with English language setting\n",
    "topic_model_english = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True)\n",
    "\n",
    "# Fit the model to your cleaned data\n",
    "topics, probs = topic_model_english.fit_transform(dataframe['text'])\n",
    "\n",
    "# Get the topics and their names\n",
    "topic_details = topic_model_english.get_topic_info()\n",
    "topic_names = {row['Topic']: row['Name'] for index, row in topic_details.iterrows()}\n",
    "\n",
    "# Assign topics to each row in the dataset\n",
    "dataframe['Topic'] = topics\n",
    "dataframe['Topic Name'] = dataframe['Topic'].apply(lambda topic_num: topic_names.get(topic_num, 'Unknown'))\n",
    "dataframe['Topic Representation'] = dataframe['Topic'].apply(lambda topic_num: ', '.join(term for term, _ in topic_model_english.get_topic(topic_num)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "791e2896-6019-4b33-b939-fbf4acb57164",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model_english.get_topic_info().to_csv('TOPICS-Biden-context.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c12440-841f-4e0e-a42e-637624417ef8",
   "metadata": {},
   "source": [
    "    - Version 2: Basic BERTopic with KeyBERT \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4df026c4-02bb-4ca3-aa11-0b56fe12f5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from bertopic import BERTopic\n",
    "from bertopic.vectorizers import ClassTfidfTransformer\n",
    "from bertopic.representation import KeyBERTInspired\n",
    "\n",
    "# Set the environment variable to disable parallelism\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Load English stopwords from NLTK\n",
    "english_stopwords = stopwords.words('english')\n",
    "\n",
    "# Step 1 - Extract embeddings\n",
    "embedding_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Step 2 - Reduce dimensionality\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine')\n",
    "\n",
    "# Step 3 - Cluster reduced embeddings\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=15, metric='euclidean', cluster_selection_method='eom', prediction_data=True)\n",
    "\n",
    "# Step 4 - Tokenize topics\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "# Step 5 - Create topic representation\n",
    "ctfidf_model = ClassTfidfTransformer()\n",
    "\n",
    "# Step 6 - (Optional) Fine-tune topic representations with a `bertopic.representation` model\n",
    "representation_model = KeyBERTInspired()\n",
    "\n",
    "# Create BERTopic model with custom settings\n",
    "topic_model = BERTopic(\n",
    "  embedding_model=embedding_model,          # Step 1 - Extract embeddings\n",
    "  umap_model=umap_model,                    # Step 2 - Reduce dimensionality\n",
    "  hdbscan_model=hdbscan_model,              # Step 3 - Cluster reduced embeddings\n",
    "  vectorizer_model=vectorizer_model,        # Step 4 - Tokenize topics\n",
    "  ctfidf_model=ctfidf_model,                # Step 5 - Extract topic words\n",
    "  representation_model=representation_model # Step 6 - (Optional) Fine-tune topic representations\n",
    ")\n",
    "\n",
    "# Fit the model to your cleaned data\n",
    "topics, probs = topic_model.fit_transform(dataframe['text'])\n",
    "\n",
    "# Get the topics and their names\n",
    "topic_details = topic_model.get_topic_info()\n",
    "topic_names = {row['Topic']: row['Name'] for index, row in topic_details.iterrows()}\n",
    "\n",
    "# Assign topics to each row in the dataset\n",
    "dataframe['Topic'] = topics\n",
    "dataframe['Topic Name'] = dataframe['Topic'].apply(lambda topic_num: topic_names.get(topic_num, 'Unknown'))\n",
    "dataframe['Topic Representation'] = dataframe['Topic'].apply(lambda topic_num: ', '.join(term for term, _ in topic_model.get_topic(topic_num)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b505aa6-c0cc-4cf7-aba3-6c6824e9a966",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info().to_csv('TOPICS-Biden-context-keybert.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c78db5c-b9ba-4acb-bc69-db9f406afcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>538</td>\n",
       "      <td>-1_biden_trump_donald_barack</td>\n",
       "      <td>[biden, trump, donald, barack, presidential, p...</td>\n",
       "      <td>[An image shared on Facebook purportedly shows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>0_biden_image_photo_posing</td>\n",
       "      <td>[biden, image, photo, posing, photograph, pict...</td>\n",
       "      <td>[An image shared on Facebook purportedly shows...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>103</td>\n",
       "      <td>1_biden_votes_electors_electoral</td>\n",
       "      <td>[biden, votes, electors, electoral, voters, ba...</td>\n",
       "      <td>[Some 2,600 uncounted votes, a majority of whi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>97</td>\n",
       "      <td>2_biden_video_joe_chanting</td>\n",
       "      <td>[biden, video, joe, chanting, presidential, ch...</td>\n",
       "      <td>[A YouTube video shared on Facebook purportedl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>3_biden_oil_fuels_petroleum</td>\n",
       "      <td>[biden, oil, fuels, petroleum, gas, gasoline, ...</td>\n",
       "      <td>[Low gas prices in Russia, Kuwait and Saudi Ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>4_covid_vaccine_vaccines_vaccinations</td>\n",
       "      <td>[covid, vaccine, vaccines, vaccinations, vacci...</td>\n",
       "      <td>[A viral Facebook post shared over 18,000 time...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>63</td>\n",
       "      <td>5_pelosi_cruz_biden_ted</td>\n",
       "      <td>[pelosi, cruz, biden, ted, nancy, republican, ...</td>\n",
       "      <td>[A video shared on Facebook claims Republican ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>56</td>\n",
       "      <td>6_biden_funding_obama_obamas</td>\n",
       "      <td>[biden, funding, obama, obamas, trillion, mill...</td>\n",
       "      <td>[President Joe Biden claimed in a forum Oct. 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>54</td>\n",
       "      <td>7_biden_pence_harris_pelosi</td>\n",
       "      <td>[biden, pence, harris, pelosi, presidential, c...</td>\n",
       "      <td>[A video shows U.S. President Joe Biden accide...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8</td>\n",
       "      <td>54</td>\n",
       "      <td>8_immigration_deportations_immigrants_migrants</td>\n",
       "      <td>[immigration, deportations, immigrants, migran...</td>\n",
       "      <td>[Under U.S. President Joe Biden's administrati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "      <td>9_biden_trump_joebiden_presidential</td>\n",
       "      <td>[biden, trump, joebiden, presidential, donald,...</td>\n",
       "      <td>[A viral Facebook post claims President Donald...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "      <td>10_taxes_tax_irs_biden</td>\n",
       "      <td>[taxes, tax, irs, biden, income, percent, fede...</td>\n",
       "      <td>[Says Joe Biden wants to put a 3% annual feder...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11</td>\n",
       "      <td>39</td>\n",
       "      <td>11_biden_putin_ukraine_impeach</td>\n",
       "      <td>[biden, putin, ukraine, impeach, ukrainian, ru...</td>\n",
       "      <td>[As Biden and Putin Talk, Disinfo from Ukraine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>32</td>\n",
       "      <td>12_biden_medicare_obamacare_uninsured</td>\n",
       "      <td>[biden, medicare, obamacare, uninsured, senior...</td>\n",
       "      <td>[In 1983, Joe Biden voted in favor of taxing 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>29</td>\n",
       "      <td>13_mask_masks_maskless_biden</td>\n",
       "      <td>[mask, masks, maskless, biden, face, photograp...</td>\n",
       "      <td>[A photograph shows 2020 Democratic presidenti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>29</td>\n",
       "      <td>14_kneeling_biden_kneeled_knelt</td>\n",
       "      <td>[kneeling, biden, kneeled, knelt, knee, kneels...</td>\n",
       "      <td>[The new US President Joe Biden kneeling and a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>27</td>\n",
       "      <td>15_biden_orders_presidency_president</td>\n",
       "      <td>[biden, orders, presidency, president, order, ...</td>\n",
       "      <td>[A post shared on Facebook claims President Jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>16_jill_biden_lady_photograph</td>\n",
       "      <td>[jill, biden, lady, photograph, wife, posing, ...</td>\n",
       "      <td>[A video shared on Twitter purportedly shows F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>17_amendment_biden_unconstitutional_constitution</td>\n",
       "      <td>[amendment, biden, unconstitutional, constitut...</td>\n",
       "      <td>[Linn County Sheriff Tim Mueller sent a letter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>23</td>\n",
       "      <td>18_biden_troops_servicemen_soldiers</td>\n",
       "      <td>[biden, troops, servicemen, soldiers, taliban,...</td>\n",
       "      <td>[A video shows members of the National Guard t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>19_biden_refused_benedict_pope</td>\n",
       "      <td>[biden, refused, benedict, pope, obama, commun...</td>\n",
       "      <td>[In October 2019, the Rev. Robert Morey of St....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count                                              Name  \\\n",
       "0      -1    538                      -1_biden_trump_donald_barack   \n",
       "1       0    125                        0_biden_image_photo_posing   \n",
       "2       1    103                  1_biden_votes_electors_electoral   \n",
       "3       2     97                        2_biden_video_joe_chanting   \n",
       "4       3     91                       3_biden_oil_fuels_petroleum   \n",
       "5       4     74             4_covid_vaccine_vaccines_vaccinations   \n",
       "6       5     63                           5_pelosi_cruz_biden_ted   \n",
       "7       6     56                      6_biden_funding_obama_obamas   \n",
       "8       7     54                       7_biden_pence_harris_pelosi   \n",
       "9       8     54    8_immigration_deportations_immigrants_migrants   \n",
       "10      9     46               9_biden_trump_joebiden_presidential   \n",
       "11     10     45                            10_taxes_tax_irs_biden   \n",
       "12     11     39                    11_biden_putin_ukraine_impeach   \n",
       "13     12     32             12_biden_medicare_obamacare_uninsured   \n",
       "14     13     29                      13_mask_masks_maskless_biden   \n",
       "15     14     29                   14_kneeling_biden_kneeled_knelt   \n",
       "16     15     27              15_biden_orders_presidency_president   \n",
       "17     16     27                     16_jill_biden_lady_photograph   \n",
       "18     17     23  17_amendment_biden_unconstitutional_constitution   \n",
       "19     18     23               18_biden_troops_servicemen_soldiers   \n",
       "20     19     21                    19_biden_refused_benedict_pope   \n",
       "\n",
       "                                       Representation  \\\n",
       "0   [biden, trump, donald, barack, presidential, p...   \n",
       "1   [biden, image, photo, posing, photograph, pict...   \n",
       "2   [biden, votes, electors, electoral, voters, ba...   \n",
       "3   [biden, video, joe, chanting, presidential, ch...   \n",
       "4   [biden, oil, fuels, petroleum, gas, gasoline, ...   \n",
       "5   [covid, vaccine, vaccines, vaccinations, vacci...   \n",
       "6   [pelosi, cruz, biden, ted, nancy, republican, ...   \n",
       "7   [biden, funding, obama, obamas, trillion, mill...   \n",
       "8   [biden, pence, harris, pelosi, presidential, c...   \n",
       "9   [immigration, deportations, immigrants, migran...   \n",
       "10  [biden, trump, joebiden, presidential, donald,...   \n",
       "11  [taxes, tax, irs, biden, income, percent, fede...   \n",
       "12  [biden, putin, ukraine, impeach, ukrainian, ru...   \n",
       "13  [biden, medicare, obamacare, uninsured, senior...   \n",
       "14  [mask, masks, maskless, biden, face, photograp...   \n",
       "15  [kneeling, biden, kneeled, knelt, knee, kneels...   \n",
       "16  [biden, orders, presidency, president, order, ...   \n",
       "17  [jill, biden, lady, photograph, wife, posing, ...   \n",
       "18  [amendment, biden, unconstitutional, constitut...   \n",
       "19  [biden, troops, servicemen, soldiers, taliban,...   \n",
       "20  [biden, refused, benedict, pope, obama, commun...   \n",
       "\n",
       "                                  Representative_Docs  \n",
       "0   [An image shared on Facebook purportedly shows...  \n",
       "1   [An image shared on Facebook purportedly shows...  \n",
       "2   [Some 2,600 uncounted votes, a majority of whi...  \n",
       "3   [A YouTube video shared on Facebook purportedl...  \n",
       "4   [Low gas prices in Russia, Kuwait and Saudi Ar...  \n",
       "5   [A viral Facebook post shared over 18,000 time...  \n",
       "6   [A video shared on Facebook claims Republican ...  \n",
       "7   [President Joe Biden claimed in a forum Oct. 2...  \n",
       "8   [A video shows U.S. President Joe Biden accide...  \n",
       "9   [Under U.S. President Joe Biden's administrati...  \n",
       "10  [A viral Facebook post claims President Donald...  \n",
       "11  [Says Joe Biden wants to put a 3% annual feder...  \n",
       "12  [As Biden and Putin Talk, Disinfo from Ukraine...  \n",
       "13  [In 1983, Joe Biden voted in favor of taxing 5...  \n",
       "14  [A photograph shows 2020 Democratic presidenti...  \n",
       "15  [The new US President Joe Biden kneeling and a...  \n",
       "16  [A post shared on Facebook claims President Jo...  \n",
       "17  [A video shared on Twitter purportedly shows F...  \n",
       "18  [Linn County Sheriff Tim Mueller sent a letter...  \n",
       "19  [A video shows members of the National Guard t...  \n",
       "20  [In October 2019, the Rev. Robert Morey of St....  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229b6fff-2d6f-4ef7-86aa-def5ee3b3a48",
   "metadata": {},
   "source": [
    "     - Version 3: Basic BERTopic with multiple iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3fde835-be4e-4f61-b59c-50505d1b60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# Set the environment variable to disable parallelism\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def process_dataset(dataframe: pd.DataFrame, dataset_name: str, num_runs: int) -> None:\n",
    "    # Load English stopwords from NLTK\n",
    "    english_stopwords = stopwords.words('english')\n",
    "\n",
    "    # # Initial cleaning of the 'text' column by removing stopwords\n",
    "    # dataframe['text'] = dataframe['text'].astype(str).apply(\n",
    "    #     lambda x: ' '.join([word for word in x.split() if word.lower() not in english_stopwords])\n",
    "    # )\n",
    "\n",
    "    for run_number in range(1, num_runs + 1):\n",
    "        run_folder = f\"BERTopic_run_{run_number}\"\n",
    "        os.makedirs(run_folder, exist_ok=True)\n",
    "\n",
    "        if run_number > 1:\n",
    "            # Load the outliers from the previous run's folder\n",
    "            previous_run_folder = f\"BERTopic_run_{run_number - 1}\"\n",
    "            outliers_filename = os.path.join(previous_run_folder, f\"BERTopic_run_{run_number - 1}_Outliers.csv\")\n",
    "            try:\n",
    "                dataframe = pd.read_csv(outliers_filename)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File {outliers_filename} not found. Ending the process.\")\n",
    "                break\n",
    "\n",
    "        # Create BERTopic model with default settings\n",
    "        topic_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True)\n",
    "\n",
    "        topics, probabilities = topic_model.fit_transform(dataframe['text'])\n",
    "\n",
    "        # Add topic labels to the dataframe\n",
    "        topic_names = topic_model.get_topic_info()['Name'].to_dict()\n",
    "        dataframe['Topic'] = topics\n",
    "        dataframe['Topic Name'] = dataframe['Topic'].apply(lambda t: topic_names.get(t, 'Unknown'))\n",
    "\n",
    "        # Save the dataframe with topic labels\n",
    "        labeled_data_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_LabeledData.csv\")\n",
    "        dataframe.to_csv(labeled_data_filename, index=False)\n",
    "\n",
    "        # Save 'Topic Name' column to a npy file\n",
    "        npy_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_TopicNames.npy\")\n",
    "        np.save(npy_filename, dataframe['Topic Name'].values)\n",
    "\n",
    "        # Output Generated Topics and Automatic Labelling\n",
    "        topic_info = topic_model.get_topic_info()\n",
    "\n",
    "        # Save BERTopic results for this run\n",
    "        bertopic_results_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Results.csv\")\n",
    "        topic_info.to_csv(bertopic_results_filename, index=False)\n",
    "\n",
    "        # Save each topic's documents to separate CSV files named after the topic's generated name\n",
    "        for topic in set(topics):\n",
    "            if topic != -1:  # Exclude outlier topic\n",
    "                topic_indices = [i for i, t in enumerate(topics) if t == topic]\n",
    "                topic_documents = dataframe.iloc[topic_indices]\n",
    "                topic_name = topic_info[topic_info['Topic'] == topic]['Name'].values[0]\n",
    "                topic_name = topic_name.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                topic_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_{topic_name}.csv\")\n",
    "                topic_documents.to_csv(topic_filename, index=False)\n",
    "\n",
    "        # Identify Outliers\n",
    "        outlier_indices = [i for i, topic in enumerate(topics) if topic == -1]\n",
    "\n",
    "        # Save the outliers if any\n",
    "        if len(outlier_indices) > 0:\n",
    "            outliers_dataframe = dataframe.iloc[outlier_indices]\n",
    "            outliers_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Outliers.csv\")\n",
    "            outliers_dataframe.to_csv(outliers_filename, index=False)\n",
    "        else:\n",
    "            # No outliers, end the process\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52c3472c-1f0d-41ba-954b-e812a6b31528",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-03 13:45:37,495 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e8ff79b8d334a6d96cc4eb8ba8e5d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-03 13:45:38,110 - BERTopic - Embedding - Completed ✓\n",
      "2024-02-03 13:45:38,111 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-02-03 13:45:43,738 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-02-03 13:45:43,740 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-02-03 13:45:43,896 - BERTopic - Cluster - Completed ✓\n",
      "2024-02-03 13:45:43,900 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-02-03 13:45:43,973 - BERTopic - Representation - Completed ✓\n",
      "2024-02-03 13:45:44,253 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecbcb435070f4317a3d1a301f68da4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-03 13:45:44,554 - BERTopic - Embedding - Completed ✓\n",
      "2024-02-03 13:45:44,554 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-02-03 13:45:46,903 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-02-03 13:45:46,904 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-02-03 13:45:46,926 - BERTopic - Cluster - Completed ✓\n",
      "2024-02-03 13:45:46,929 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-02-03 13:45:46,953 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "# process_dataset(dataframe, dataframe_topic_summary_give a name, num_runs)\n",
    "process_dataset(dataframe, \"BERT_Topics\",2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9798a2d8-0b52-4372-8614-40047663708f",
   "metadata": {},
   "source": [
    "      - Version 4: Basic BERTopic with multiple iterations with KeyBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c90c1d98-106d-480b-938e-7b02943be6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired  # Import the custom representation model\n",
    "\n",
    "# Set the environment variable to disable parallelism\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def process_dataset(dataframe: pd.DataFrame, dataset_name: str, num_runs: int) -> None:\n",
    "    # Load English stopwords from NLTK\n",
    "    english_stopwords = stopwords.words('english')\n",
    "    # Initialize the representation model\n",
    "    representation_model = KeyBERTInspired()\n",
    "\n",
    "    for run_number in range(1, num_runs + 1):\n",
    "        run_folder = f\"BERTopic_run_{run_number}\"\n",
    "        os.makedirs(run_folder, exist_ok=True)\n",
    "\n",
    "        if run_number > 1:\n",
    "            # Load the outliers from the previous run's folder\n",
    "            previous_run_folder = f\"BERTopic_run_{run_number - 1}\"\n",
    "            outliers_filename = os.path.join(previous_run_folder, f\"BERTopic_run_{run_number - 1}_Outliers.csv\")\n",
    "            try:\n",
    "                dataframe = pd.read_csv(outliers_filename)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File {outliers_filename} not found. Ending the process.\")\n",
    "                break\n",
    "\n",
    "        # Create BERTopic model with custom representation model\n",
    "        topic_model = BERTopic(\n",
    "            language=\"english\",\n",
    "            calculate_probabilities=True,\n",
    "            verbose=True,\n",
    "            representation_model=representation_model  # Add the custom representation model\n",
    "        )\n",
    "\n",
    "        topics, probabilities = topic_model.fit_transform(dataframe['text'])\n",
    "\n",
    "        # Add topic labels to the dataframe\n",
    "        topic_names = topic_model.get_topic_info()['Name'].to_dict()\n",
    "        dataframe['Topic'] = topics\n",
    "        dataframe['Topic Name'] = dataframe['Topic'].apply(lambda t: topic_names.get(t, 'Unknown'))\n",
    "\n",
    "        # Save the dataframe with topic labels\n",
    "        labeled_data_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_LabeledData.csv\")\n",
    "        dataframe.to_csv(labeled_data_filename, index=False)\n",
    "\n",
    "        # Save 'Topic Name' column to a npy file\n",
    "        npy_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_TopicNames.npy\")\n",
    "        np.save(npy_filename, dataframe['Topic Name'].values)\n",
    "\n",
    "        # Output Generated Topics and Automatic Labelling\n",
    "        topic_info = topic_model.get_topic_info()\n",
    "\n",
    "        # Save BERTopic results for this run\n",
    "        bertopic_results_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Results.csv\")\n",
    "        topic_info.to_csv(bertopic_results_filename, index=False)\n",
    "\n",
    "        # Save each topic's documents to separate CSV files named after the topic's generated name\n",
    "        for topic in set(topics):\n",
    "            if topic != -1:  # Exclude outlier topic\n",
    "                topic_indices = [i for i, t in enumerate(topics) if t == topic]\n",
    "                topic_documents = dataframe.iloc[topic_indices]\n",
    "                topic_name = topic_info[topic_info['Topic'] == topic]['Name'].values[0]\n",
    "                topic_name = topic_name.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                topic_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_{topic_name}.csv\")\n",
    "                topic_documents.to_csv(topic_filename, index=False)\n",
    "\n",
    "        # Identify Outliers\n",
    "        outlier_indices = [i for i, topic in enumerate(topics) if topic == -1]\n",
    "\n",
    "        # Save the outliers if any\n",
    "        if len(outlier_indices) > 0:\n",
    "            outliers_dataframe = dataframe.iloc[outlier_indices]\n",
    "            outliers_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Outliers.csv\")\n",
    "            outliers_dataframe.to_csv(outliers_filename, index=False)\n",
    "        else:\n",
    "            # No outliers, end the process\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa56a790-3f61-43c5-9f03-0b3a37e404d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 16:53:40,496 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ab7dd033734d1993b99da423020d43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 16:53:41,032 - BERTopic - Embedding - Completed ✓\n",
      "2024-02-05 16:53:41,033 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-02-05 16:53:46,055 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-02-05 16:53:46,058 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-02-05 16:53:46,197 - BERTopic - Cluster - Completed ✓\n",
      "2024-02-05 16:53:46,201 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-02-05 16:53:46,721 - BERTopic - Representation - Completed ✓\n",
      "2024-02-05 16:53:46,998 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af4325a98144076961e2a73c9f94cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 16:53:47,327 - BERTopic - Embedding - Completed ✓\n",
      "2024-02-05 16:53:47,328 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-02-05 16:53:49,637 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-02-05 16:53:49,637 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-02-05 16:53:49,660 - BERTopic - Cluster - Completed ✓\n",
      "2024-02-05 16:53:49,663 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-02-05 16:53:49,798 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "# process_dataset(dataframe, dataframe_topic_summary_give a name, num_runs)\n",
    "process_dataset(dataframe, \"BERT_Topics\",2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe65fb2-184e-4e2f-a3f5-4df84df18ac9",
   "metadata": {},
   "source": [
    "      - Version 5: Basic BERTopic with multiple iterations. Fixing the labelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d226dc66-259d-42a4-9d8b-54403b0c5d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# Set the environment variable to disable parallelism\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def process_dataset(dataframe: pd.DataFrame, dataset_name: str, num_runs: int) -> None:\n",
    "    # Load English stopwords from NLTK (This part of the code was commented out in your original script)\n",
    "    #english_stopwords = stopwords.words('english')\n",
    "\n",
    "    for run_number in range(1, num_runs + 1):\n",
    "        run_folder = f\"BERTopic_run_{run_number}\"\n",
    "        os.makedirs(run_folder, exist_ok=True)\n",
    "\n",
    "        if run_number > 1:\n",
    "            # Correctly load outliers from the previous run\n",
    "            outliers_filename = os.path.join(f\"BERTopic_run_{run_number - 1}\", f\"BERTopic_run_{run_number - 1}_Outliers.csv\")\n",
    "            try:\n",
    "                dataframe = pd.read_csv(outliers_filename)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File {outliers_filename} not found. Ending the process.\")\n",
    "                break\n",
    "\n",
    "        # Create BERTopic model with default settings\n",
    "        topic_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True)\n",
    "        topics, probabilities = topic_model.fit_transform(dataframe['text'])\n",
    "\n",
    "        # Add topic labels to the dataframe\n",
    "        topic_info = topic_model.get_topic_info()  # Get topic information\n",
    "        topic_names = {row['Topic']: row['Name'] for index, row in topic_info.iterrows()}\n",
    "        dataframe['Topic'] = topics\n",
    "        dataframe['Topic Name'] = dataframe['Topic'].apply(lambda t: topic_names.get(t, 'Unknown'))\n",
    "\n",
    "        # Save the dataframe with topic labels\n",
    "        labeled_data_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_TopicLabels.csv\")\n",
    "        dataframe.to_csv(labeled_data_filename, index=False)\n",
    "\n",
    "        # Save 'Topic Name' column to a npy file\n",
    "        npy_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_TopicNames.npy\")\n",
    "        np.save(npy_filename, dataframe['Topic Name'].values)\n",
    "\n",
    "        # Save BERTopic results with consistent naming\n",
    "        bertopic_results_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Topics_Results.csv\")\n",
    "        topic_info.to_csv(bertopic_results_filename, index=False)\n",
    "\n",
    "        # Save documents for each topic with the simplified naming convention\n",
    "        for topic, name in topic_names.items():\n",
    "            if topic != -1:  # Excluding outlier topic\n",
    "                topic_indices = dataframe[dataframe['Topic'] == topic].index\n",
    "                topic_dataframe = dataframe.loc[topic_indices]\n",
    "                clean_name = name.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                topic_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Topic_{topic}_{clean_name}.csv\")\n",
    "                topic_dataframe.to_csv(topic_filename, index=False)\n",
    "\n",
    "        # Handle outliers, saving them with consistent naming\n",
    "        outlier_indices = dataframe[dataframe['Topic'] == -1].index\n",
    "        if outlier_indices.any():\n",
    "            outliers_dataframe = dataframe.loc[outlier_indices]\n",
    "            outliers_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Outliers.csv\")\n",
    "            outliers_dataframe.to_csv(outliers_filename, index=False)\n",
    "        else:\n",
    "            print(\"No outliers found in this run. Ending the process.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cef5a59-41d3-4280-9370-db54e3cf85f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 11:53:41,984 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ec333980af445a9bc9fdd906695d325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 11:53:42,524 - BERTopic - Embedding - Completed ✓\n",
      "2024-02-24 11:53:42,524 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-02-24 11:53:48,819 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-02-24 11:53:48,822 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-02-24 11:53:48,973 - BERTopic - Cluster - Completed ✓\n",
      "2024-02-24 11:53:48,980 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-02-24 11:53:49,051 - BERTopic - Representation - Completed ✓\n",
      "2024-02-24 11:53:49,368 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1769fb1a8d3c45a19e6d0cdf5065d007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 11:53:49,665 - BERTopic - Embedding - Completed ✓\n",
      "2024-02-24 11:53:49,665 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-02-24 11:53:51,893 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-02-24 11:53:51,893 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-02-24 11:53:51,916 - BERTopic - Cluster - Completed ✓\n",
      "2024-02-24 11:53:51,918 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-02-24 11:53:51,942 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "# process_dataset(dataframe, dataframe_topic_summary_give a name, num_runs)\n",
    "process_dataset(dataframe, \"BERT_Topics\",2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d44216-5148-4b91-acc4-1518fcde3f73",
   "metadata": {},
   "source": [
    "      - Version 6: Basic BERTopic with multiple iterations with KeyBert. Fixing the labelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ddeaa5f-f3de-49e9-9f63-391173a7ba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "\n",
    "# Set the environment variable to disable parallelism\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def process_dataset(dataframe: pd.DataFrame, dataset_name: str, num_runs: int) -> None:\n",
    "    # Load English stopwords from NLTK (Commented as it's not used in the provided code snippet)\n",
    "    # english_stopwords = stopwords.words('english')\n",
    "    \n",
    "    for run_number in range(1, num_runs + 1):\n",
    "        run_folder = f\"BERTopic_run_{run_number}\"\n",
    "        os.makedirs(run_folder, exist_ok=True)\n",
    "\n",
    "        if run_number > 1:\n",
    "            # Correctly load the outliers from the previous run\n",
    "            outliers_filename = os.path.join(f\"BERTopic_run_{run_number - 1}\", f\"BERTopic_run_{run_number - 1}_Outliers.csv\")\n",
    "            try:\n",
    "                dataframe = pd.read_csv(outliers_filename)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File {outliers_filename} not found. Ending the process.\")\n",
    "                break\n",
    "\n",
    "        # Create BERTopic model with default settings\n",
    "        topic_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True)\n",
    "        topics, probabilities = topic_model.fit_transform(dataframe['text'])\n",
    "\n",
    "        # Generate topic names and update the dataframe with these names\n",
    "        topic_info = topic_model.get_topic_info()  # Get topic information\n",
    "        topic_names = {row['Topic']: row['Name'] for index, row in topic_info.iterrows()}\n",
    "        dataframe['Topic'] = topics\n",
    "        dataframe['Topic Name'] = dataframe['Topic'].apply(lambda t: topic_names.get(t, 'Unknown'))\n",
    "\n",
    "        # Save the dataframe with topic labels using the updated naming convention\n",
    "        labeled_data_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_TopicLabels.csv\")\n",
    "        dataframe.to_csv(labeled_data_filename, index=False)\n",
    "\n",
    "        # Save 'Topic Name' column to a npy file using the updated naming convention\n",
    "        npy_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_TopicNames.npy\")\n",
    "        np.save(npy_filename, dataframe['Topic Name'].values)\n",
    "\n",
    "        # Save BERTopic results with the updated naming convention\n",
    "        bertopic_results_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Topics_Results.csv\")\n",
    "        topic_info.to_csv(bertopic_results_filename, index=False)\n",
    "\n",
    "        # Save documents for each topic using the simplified naming convention\n",
    "        for topic, name in topic_names.items():\n",
    "            if topic != -1:  # Excluding outlier topic\n",
    "                topic_indices = dataframe[dataframe['Topic'] == topic].index\n",
    "                topic_dataframe = dataframe.loc[topic_indices]\n",
    "                clean_name = name.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                topic_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Topic_{topic}_{clean_name}.csv\")\n",
    "                topic_dataframe.to_csv(topic_filename, index=False)\n",
    "\n",
    "        # Handle outliers, saving them with consistent naming\n",
    "        outlier_indices = dataframe[dataframe['Topic'] == -1].index\n",
    "        if len(outlier_indices) > 0:\n",
    "            outliers_dataframe = dataframe.loc[outlier_indices]\n",
    "            outliers_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Outliers.csv\")\n",
    "            outliers_dataframe.to_csv(outliers_filename, index=False)\n",
    "        else:\n",
    "            print(\"No outliers found in this run. Ending the process.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e39a080-3d9a-4426-b0ff-8b11a6aa37ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 12:00:01,239 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca171ca637fe43049a00de4def9e3e61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 12:00:02,396 - BERTopic - Embedding - Completed ✓\n",
      "2024-02-24 12:00:02,396 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-02-24 12:00:07,886 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-02-24 12:00:07,888 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-02-24 12:00:08,035 - BERTopic - Cluster - Completed ✓\n",
      "2024-02-24 12:00:08,038 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-02-24 12:00:08,105 - BERTopic - Representation - Completed ✓\n",
      "2024-02-24 12:00:10,849 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4048277956f476f8a649102f19ed777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 12:00:11,483 - BERTopic - Embedding - Completed ✓\n",
      "2024-02-24 12:00:11,483 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-02-24 12:00:13,767 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-02-24 12:00:13,768 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-02-24 12:00:13,792 - BERTopic - Cluster - Completed ✓\n",
      "2024-02-24 12:00:13,796 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-02-24 12:00:13,817 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No outliers found in this run. Ending the process.\n"
     ]
    }
   ],
   "source": [
    "# process_dataset(dataframe, dataframe_topic_summary_give a name, num_runs)\n",
    "process_dataset(dataframe, \"BERT_Topics\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5267bcac-418d-4d71-895d-4aef50478f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import KeyBERTInspired  # Import the custom representation model\n",
    "\n",
    "# Set the environment variable to disable parallelism\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def process_dataset(dataframe: pd.DataFrame, dataset_name: str, num_runs: int) -> None:\n",
    "    # Initialize the representation model\n",
    "    representation_model = KeyBERTInspired()\n",
    "\n",
    "    for run_number in range(1, num_runs + 1):\n",
    "        run_folder = f\"BERTopic_run_{run_number}\"\n",
    "        os.makedirs(run_folder, exist_ok=True)\n",
    "\n",
    "        if run_number > 1:\n",
    "            # Correctly load the outliers from the previous run\n",
    "            outliers_filename = os.path.join(f\"BERTopic_run_{run_number - 1}\", f\"BERTopic_run_{run_number - 1}_Outliers.csv\")\n",
    "            try:\n",
    "                dataframe = pd.read_csv(outliers_filename)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File {outliers_filename} not found. Ending the process.\")\n",
    "                break\n",
    "\n",
    "        # Create BERTopic model with the custom representation model\n",
    "        topic_model = BERTopic(\n",
    "            language=\"english\",\n",
    "            calculate_probabilities=True,\n",
    "            verbose=True,\n",
    "            representation_model=representation_model  # Add the custom representation model\n",
    "        )\n",
    "\n",
    "        topics, probabilities = topic_model.fit_transform(dataframe['text'])\n",
    "\n",
    "        # Generate topic names and update the dataframe with these names\n",
    "        topic_info = topic_model.get_topic_info()  # Get topic information\n",
    "        topic_names = {row['Topic']: row['Name'] for index, row in topic_info.iterrows()}\n",
    "        dataframe['Topic'] = topics\n",
    "        dataframe['Topic Name'] = dataframe['Topic'].apply(lambda t: topic_names.get(t, 'Unknown'))\n",
    "\n",
    "        # Save the dataframe with topic labels using the updated naming convention\n",
    "        labeled_data_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_TopicLabels.csv\")\n",
    "        dataframe.to_csv(labeled_data_filename, index=False)\n",
    "\n",
    "        # Save 'Topic Name' column to a npy file using the updated naming convention\n",
    "        npy_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_TopicNames.npy\")\n",
    "        np.save(npy_filename, dataframe['Topic Name'].values)\n",
    "\n",
    "        # Save BERTopic results with the updated naming convention\n",
    "        bertopic_results_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Topics_Results.csv\")\n",
    "        topic_info.to_csv(bertopic_results_filename, index=False)\n",
    "\n",
    "        # Save documents for each topic using the simplified naming convention\n",
    "        for topic, name in topic_names.items():\n",
    "            if topic != -1:  # Excluding outlier topic\n",
    "                topic_indices = dataframe[dataframe['Topic'] == topic].index\n",
    "                topic_dataframe = dataframe.loc[topic_indices]\n",
    "                clean_name = name.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                topic_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Topic_{topic}_{clean_name}.csv\")\n",
    "                topic_dataframe.to_csv(topic_filename, index=False)\n",
    "\n",
    "        # Handle outliers, saving them with consistent naming\n",
    "        outlier_indices = dataframe[dataframe['Topic'] == -1].index\n",
    "        if len(outlier_indices) > 0:\n",
    "            outliers_dataframe = dataframe.loc[outlier_indices]\n",
    "            outliers_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Outliers.csv\")\n",
    "            outliers_dataframe.to_csv(outliers_filename, index=False)\n",
    "        else:\n",
    "            print(\"No outliers found in this run. Ending the process.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c96e84e-cd80-4feb-97ee-221805429e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 16:40:27,538 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "756d68888b274b4fa5dab6133f21704f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 16:40:28,079 - BERTopic - Embedding - Completed ✓\n",
      "2024-02-24 16:40:28,080 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-02-24 16:40:33,175 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-02-24 16:40:33,176 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-02-24 16:40:33,318 - BERTopic - Cluster - Completed ✓\n",
      "2024-02-24 16:40:33,321 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-02-24 16:40:33,832 - BERTopic - Representation - Completed ✓\n",
      "2024-02-24 16:40:34,151 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7c5d3d035c4e76874709a44f10d679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-24 16:40:34,419 - BERTopic - Embedding - Completed ✓\n",
      "2024-02-24 16:40:34,420 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-02-24 16:40:37,206 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-02-24 16:40:37,208 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-02-24 16:40:37,228 - BERTopic - Cluster - Completed ✓\n",
      "2024-02-24 16:40:37,232 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-02-24 16:40:37,343 - BERTopic - Representation - Completed ✓\n"
     ]
    }
   ],
   "source": [
    "# process_dataset(dataframe, dataframe_topic_summary_give a name, num_runs)\n",
    "process_dataset(dataframe, \"BERT_Topics\",2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "265b6c5f-e53a-471d-88ea-a9b4e8c71091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bertopic import BERTopic\n",
    "import numpy as np\n",
    "from bertopic.representation import KeyBERTInspired  # Import the custom representation model\n",
    "\n",
    "# Set the environment variable to disable parallelism\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "def process_dataset(dataframe: pd.DataFrame, dataset_name: str, num_runs: int) -> None:\n",
    "    # Initialize the representation model\n",
    "    representation_model = KeyBERTInspired()\n",
    "\n",
    "    # Specify the embedding model to be saved with the BERTopic model\n",
    "    embedding_model = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "    for run_number in range(1, num_runs + 1):\n",
    "        run_folder = f\"BERTopic_run_{run_number}\"\n",
    "        os.makedirs(run_folder, exist_ok=True)\n",
    "\n",
    "        if run_number > 1:\n",
    "            # Correctly load the outliers from the previous run\n",
    "            outliers_filename = os.path.join(f\"BERTopic_run_{run_number - 1}\", f\"BERTopic_run_{run_number - 1}_Outliers.csv\")\n",
    "            try:\n",
    "                dataframe = pd.read_csv(outliers_filename)\n",
    "            except FileNotFoundError:\n",
    "                print(f\"File {outliers_filename} not found. Ending the process.\")\n",
    "                break\n",
    "\n",
    "        # Create BERTopic model with the custom representation model\n",
    "        topic_model = BERTopic(\n",
    "            language=\"english\",\n",
    "            calculate_probabilities=True,\n",
    "            verbose=True,\n",
    "            representation_model=representation_model  # Add the custom representation model\n",
    "        )\n",
    "\n",
    "        topics, probabilities = topic_model.fit_transform(dataframe['text'])\n",
    "\n",
    "        # Generate topic names and update the dataframe with these names\n",
    "        topic_info = topic_model.get_topic_info()  # Get topic information\n",
    "        topic_names = {row['Topic']: row['Name'] for index, row in topic_info.iterrows()}\n",
    "        dataframe['Topic'] = topics\n",
    "        dataframe['Topic Name'] = dataframe['Topic'].apply(lambda t: topic_names.get(t, 'Unknown'))\n",
    "\n",
    "        # Save the dataframe with topic labels using the updated naming convention\n",
    "        labeled_data_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_TopicLabels.csv\")\n",
    "        dataframe.to_csv(labeled_data_filename, index=False)\n",
    "\n",
    "        # Save 'Topic Name' column to a npy file using the updated naming convention\n",
    "        npy_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_TopicNames.npy\")\n",
    "        np.save(npy_filename, dataframe['Topic Name'].values)\n",
    "\n",
    "        # Save BERTopic results with the updated naming convention\n",
    "        bertopic_results_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Topics_Results.csv\")\n",
    "        topic_info.to_csv(bertopic_results_filename, index=False)\n",
    "\n",
    "        # Save documents for each topic using the simplified naming convention\n",
    "        for topic, name in topic_names.items():\n",
    "            if topic != -1:  # Excluding outlier topic\n",
    "                topic_indices = dataframe[dataframe['Topic'] == topic].index\n",
    "                topic_dataframe = dataframe.loc[topic_indices]\n",
    "                clean_name = name.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                topic_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Topic_{topic}_{clean_name}.csv\")\n",
    "                topic_dataframe.to_csv(topic_filename, index=False)\n",
    "\n",
    "        # Handle outliers, saving them with consistent naming\n",
    "        outlier_indices = dataframe[dataframe['Topic'] == -1].index\n",
    "        if len(outlier_indices) > 0:\n",
    "            outliers_dataframe = dataframe.loc[outlier_indices]\n",
    "            outliers_filename = os.path.join(run_folder, f\"BERTopic_run_{run_number}_Outliers.csv\")\n",
    "            outliers_dataframe.to_csv(outliers_filename, index=False)\n",
    "        else:\n",
    "            print(\"No outliers found in this run. Ending the process.\")\n",
    "            break\n",
    "\n",
    "        # Save the BERTopic model using safetensors serialization\n",
    "        model_dir = os.path.join(run_folder, \"model_dir\")\n",
    "        topic_model.save(model_dir, serialization=\"safetensors\", save_ctfidf=True, save_embedding_model=embedding_model)\n",
    "\n",
    "        print(f\"Run {run_number}: Model and data saved successfully in {model_dir} using safetensors serialization.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff7c9f31-3900-4172-8ea7-17ce302665d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-25 21:55:06,301 - BERTopic - Embedding - Transforming documents to embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74457a639eb4921a92c5bad63acf0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/165 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-25 21:55:10,349 - BERTopic - Embedding - Completed ✓\n",
      "2024-02-25 21:55:10,350 - BERTopic - Dimensionality - Fitting the dimensionality reduction algorithm\n",
      "2024-02-25 21:55:38,024 - BERTopic - Dimensionality - Completed ✓\n",
      "2024-02-25 21:55:38,028 - BERTopic - Cluster - Start clustering the reduced embeddings\n",
      "2024-02-25 21:55:41,371 - BERTopic - Cluster - Completed ✓\n",
      "2024-02-25 21:55:41,378 - BERTopic - Representation - Extracting topics from clusters using representation models.\n",
      "2024-02-25 21:55:43,287 - BERTopic - Representation - Completed ✓\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1: Model and data saved successfully in BERTopic_run_1/model_dir using safetensors serialization.\n"
     ]
    }
   ],
   "source": [
    "# process_dataset(dataframe, dataframe_topic_summary_give a name, num_runs)\n",
    "process_dataset(dataframe, \"BERT_Topics\",1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
